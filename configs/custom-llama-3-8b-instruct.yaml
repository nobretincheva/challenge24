model: "dual_llama_3_chat"

# LLM
llm_path: "meta-llama/Meta-Llama-3-8B-Instruct"

# Prompt templates
prompt_templates_file: "challenge24/question_prompts_personas_per_entity.csv"

# Additional info prompt templates
add_info_file: "challenge24/add_info_prompts_personas_per_entity.csv"

# LLM parameters
max_new_tokens: 1000

# Quantization: useful for large models and limited computing resources
use_quantization: true

# In-context learning parameters
few_shot: 5

# Data
train_data_file: "challenge24/data/train.jsonl"